{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe-G-WiederholteFragen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemeines\n",
    "\n",
    "Eine allgemeine Beschreibung der Laboraufgaben inklusive des Vorgehens, den Bewertungsrichtlinien und der Abgabe finden Sie  <a href=\"ML-allgemein.ipynb\">hier</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenquelle\n",
    "\n",
    "\n",
    "* Laden Sie ihre Daten von http://141.72.190.207/ml_lab/G_fragen herunter\n",
    "    * Die Daten sind geschützt. \n",
    "        * Sie müssen evtl. in einem Netzwerk der DHBW (z.B. WLAN, VPN, ...) angemeldet sein. \n",
    "        * Sie können sich auf der Webseite mit dem Benutzernamen dhbw und dem Zugangsnamen ml_2021 anmelden. \n",
    "* Die Daten sind in einem anwendungsspezifischen Format gespeichert.\n",
    "    * Sie finden evtl. Informationen über die Daten in einer \"README\" Datei. \n",
    "    * Finden Sie keine solche Datei sind die Daten selbst erklärend. \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Datensammlung enthält Fragen aus einem Forum. Es sind Paare aus Fragen gleichen Inhalts geboten.\n",
    "\n",
    "Erstellen Sie ein tiefes Neuronales Netzwerk, dass dem Nutzer schon bei der Eingabe einer neuen Frage gleich ähnliche Fragen anbietet. \n",
    "* Je mehr Text der Benutzer eingibt, desto präziser sollen die ähnlichen Fragen sein! \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lösung\n",
    "\n",
    "* Beginnen Sie hier mit Ihrer Dokumentation und Implementierung! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fügen Sie ihren Code hier ein!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Vorgehen:\n",
    "- Finden von unnötigen Wörtern (in, wie usw.)\n",
    "- Extrahieren der \"wertvollen\" Informationswerten\n",
    "- Einteilen der Fragen in Kategorien und Lernen KI anhand der gelieferten Paare\n",
    "- Überprüfung anhand der Testfragen\n",
    "- Erstellung einer Eingabemaske, mit Testfragen zur überprüfung der KI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einlesen der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen der Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                           question1  \\\n0  What is the step by step guide to invest in sh...   \n1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2  How can I increase the speed of my internet co...   \n3  Why am I mentally very lonely? How can I solve...   \n4  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  \n0  What is the step by step guide to invest in sh...             0  \n1  What would happen if the Indian government sto...             0  \n2  How can Internet speed be increased by hacking...             0  \n3  Find the remainder when [math]23^{24}[/math] i...             0  \n4            Which fish would survive in salt water?             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "train_data = pd.read_csv(\n",
    "    \"./fragen/train.csv\",\n",
    "    usecols= ['question1', 'question2', 'is_duplicate'],\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "train_data.dropna(inplace=True)\n",
    "train_data.head()\n",
    "#for i in range(0, len(train_data)):\n",
    "#    if type(train_data.at[i, 'question1']) == float or type(train_data.at[i, 'question2']) == float:\n",
    "#        print(train_data.at[i, 'question2'])\n",
    "#        print(train_data.at[i, 'question1'])\n",
    "#        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Einlesen der Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4080/1675913220.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_data = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 question1  \\\ntest_id                                                      \n0        How does the Surface Pro himself 4 compare wit...   \n1        Should I have a hair transplant at age 24? How...   \n2        What but is the best way to send money from Ch...   \n3                              Which food not emulsifiers?   \n4                         How \"aberystwyth\" start reading?   \n\n                                                 question2  \ntest_id                                                     \n0        Why did Microsoft choose core m3 and not core ...  \n1              How much cost does hair transplant require?  \n2                            What you send money to China?  \n3                                        What foods fibre?  \n4                           How their can I start reading?  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n    </tr>\n    <tr>\n      <th>test_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>How does the Surface Pro himself 4 compare wit...</td>\n      <td>Why did Microsoft choose core m3 and not core ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Should I have a hair transplant at age 24? How...</td>\n      <td>How much cost does hair transplant require?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What but is the best way to send money from Ch...</td>\n      <td>What you send money to China?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Which food not emulsifiers?</td>\n      <td>What foods fibre?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How \"aberystwyth\" start reading?</td>\n      <td>How their can I start reading?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\n",
    "    \"./fragen/test.csv\",\n",
    "    index_col=\"test_id\"\n",
    ")\n",
    "\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing\n",
    "According to the tensorflow website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'What is the step by step guide to invest in share ' b'What is the step by step guide to invest in share ' tf.Tensor(0, shape=(), dtype=int64)\n",
      "b'What is the story of Kohinoor (Koh-i-Noor) Diamond' b'What would happen if the Indian government stole t' tf.Tensor(0, shape=(), dtype=int64)\n",
      "b'How can I increase the speed of my internet connec' b'How can Internet speed be increased by hacking thr' tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "target = train_data.pop('is_duplicate')\n",
    "\n",
    "ds_raw = tf.data.Dataset.from_tensor_slices((train_data.values, target.values))\n",
    "\n",
    "for ex in ds_raw.take(3):\n",
    "    print(ex[0].numpy()[0][:50], ex[0].numpy()[1][:50], ex[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unterteilung in Trainings, Validierungs und Testdaten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "ds_length = len(ds_raw)\n",
    "ds_raw_train = ds_raw.take(round(ds_length*0.8)-1)\n",
    "ds_raw_train_valid = ds_raw.take(round(ds_length*0.2)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Größe des Wörterbuches:  99353\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tokenizer = tfds.deprecated.text.Tokenizer()\n",
    "token_counts = Counter()\n",
    "\n",
    "for example in ds_raw_train:\n",
    "    for i in range(0,2):\n",
    "        tokens = tokenizer.tokenize(example[0].numpy()[i])\n",
    "        token_counts.update(tokens)\n",
    "\n",
    "print(\"Größe des Wörterbuches: \", len(token_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create a encoder and map the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "(10,)\n",
      "(14,)\n",
      "(11,)\n",
      "(13,)\n"
     ]
    }
   ],
   "source": [
    "encoder = tfds.deprecated.text.TokenTextEncoder(token_counts)\n",
    "encoder.encode('This is a example')\n",
    "\n",
    "def encode(text_tensor, label):\n",
    "    #print(text_tensor)\n",
    "    text0 = text_tensor.numpy()[0]\n",
    "    text1 = text_tensor.numpy()[1]\n",
    "    return encoder.encode(text0), encoder.encode(text1), label\n",
    "\n",
    "def encode_map_fn(text, label):\n",
    "    return tf.py_function(encode,\n",
    "                          inp=[text, label],\n",
    "                          Tout=[tf.int64, tf.int64, tf.int64])\n",
    "\n",
    "ds_train = ds_raw_train.map(encode_map_fn)\n",
    "ds_train_valid = ds_raw_train_valid.map(encode_map_fn)\n",
    "for x in ds_train.take(5):\n",
    "    print(x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Shape: (14,)\n",
      "Individual Shape: (10,)\n",
      "Individual Shape: (14,)\n",
      "Individual Shape: (11,)\n",
      "Individual Shape: (13,)\n",
      "Individual Shape: (17,)\n",
      "Individual Shape: (4,)\n",
      "Individual Shape: (7,)\n",
      "Batch Shape: (4, 14)\n",
      "(<tf.Tensor: shape=(4, 14), dtype=int64, numpy=\n",
      "array([[ 1,  2,  3,  4,  5,  4,  6,  7,  8,  9, 10, 11,  9, 12],\n",
      "       [ 1,  2,  3, 13, 14, 15, 16, 17, 18, 19,  0,  0,  0,  0],\n",
      "       [28, 29, 30, 31,  3, 32, 14, 33, 34, 35, 36, 37, 38, 39],\n",
      "       [46, 47, 30, 48, 49, 50, 28, 29, 30, 51, 52,  0,  0,  0]])>, <tf.Tensor: shape=(4, 15), dtype=int64, numpy=\n",
      "array([[ 1,  2,  3,  4,  5,  4,  6,  7,  8,  9, 10, 11,  0,  0,  0],\n",
      "       [ 1, 20, 21, 22,  3, 23, 24, 25,  3, 15, 16, 17, 18, 26, 27],\n",
      "       [28, 29, 40, 32, 41, 42,  5, 43, 44, 45,  0,  0,  0,  0,  0],\n",
      "       [53,  3, 54, 55, 56, 57, 58, 56,  2, 59,  5, 58, 57,  0,  0]])>, <tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 0, 0, 0])>)\n",
      "Batch Shape: (4, 17)\n",
      "(<tf.Tensor: shape=(4, 17), dtype=int64, numpy=\n",
      "array([[ 60,  61,  62,   9,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "          0,   0,   0,   0],\n",
      "       [ 74,  30,  47,  38,  75,  76,  77,  78,  68,  79,  80,  81,  82,\n",
      "         83,  84,  85,  86],\n",
      "       [ 92,  30,  93,  94,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0],\n",
      "       [ 28,  29,  30,  41,  38, 103, 104,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0]])>, <tf.Tensor: shape=(4, 17), dtype=int64, numpy=\n",
      "array([[ 60,  72,  20,  73,   9,  66,  63,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0],\n",
      "       [ 30,  87,  38,  88,  75,  76,  89,  68,  90,   9,  75,   1,  82,\n",
      "         91,  84,  85,  86],\n",
      "       [  1,  95,  96,  97,  68,  98,  99, 100,  68, 101, 102,   0,   0,\n",
      "          0,   0,   0,   0],\n",
      "       [  1, 105,  30, 106,   7,  41,  38, 107, 104,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0]])>, <tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 1, 0, 1])>)\n"
     ]
    }
   ],
   "source": [
    "## Take a small subset\n",
    "ds_subset = ds_train.take(8)\n",
    "for example in ds_subset:\n",
    "    print('Individual Shape:', example[0].shape)\n",
    "\n",
    "## batching the datasets\n",
    "ds_batched = ds_subset.padded_batch(\n",
    "    4, padded_shapes=([-1], [-1], []))\n",
    "\n",
    "for batch in ds_batched:\n",
    "    print('Batch Shape:', batch[0].shape)\n",
    "    print(batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Batch the data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Shape: tf.Tensor([0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1], shape=(32,), dtype=int64)\n",
      "Individual Shape: tf.Tensor([1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0], shape=(32,), dtype=int64)\n",
      "Individual Shape: tf.Tensor([0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1], shape=(32,), dtype=int64)\n",
      "Individual Shape: tf.Tensor([0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1], shape=(32,), dtype=int64)\n",
      "Individual Shape: tf.Tensor([0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1], shape=(32,), dtype=int64)\n",
      "Individual Shape: tf.Tensor([1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1], shape=(32,), dtype=int64)\n",
      "Individual Shape: tf.Tensor([0 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0], shape=(32,), dtype=int64)\n",
      "Individual Shape: tf.Tensor([1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "train_data = ds_train.padded_batch( 32, padded_shapes=([-1],[-1],[]))\n",
    "\n",
    "valid_data = ds_train_valid.padded_batch( 32, padded_shapes=([-1],[-1],[]))\n",
    "\n",
    "#test_data  = ds_test.padded_batch ( 32, padded_shapes=([-1],[-1],[]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add the trainings-modell"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Größe Wörterbuch + 2 99355\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          3179360   \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, None, 32)          2080      \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,183,553\n",
      "Trainable params: 3,183,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "size_dic = len(token_counts) + 2\n",
    "print(\"Größe Wörterbuch + 2\", size_dic)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(size_dic, output_dim = 32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% m\n"
    }
   },
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_data, validation_data=valid_data, epochs=10)"
   ],
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10108/10108 [==============================] - 355s 35ms/step - loss: -4745.5591 - accuracy: 0.0133 - val_loss: -4192.2656 - val_accuracy: 0.0129\n",
      "Epoch 2/10\n",
      "10108/10108 [==============================] - 360s 36ms/step - loss: -4746.2764 - accuracy: 0.0130 - val_loss: -4192.2656 - val_accuracy: 0.0129\n",
      "Epoch 3/10\n",
      "10108/10108 [==============================] - 363s 36ms/step - loss: -4746.2764 - accuracy: 0.0130 - val_loss: -4192.2656 - val_accuracy: 0.0129\n",
      "Epoch 4/10\n",
      "10108/10108 [==============================] - 363s 36ms/step - loss: -4746.2764 - accuracy: 0.0130 - val_loss: -4192.2656 - val_accuracy: 0.0129\n",
      "Epoch 5/10\n",
      "10108/10108 [==============================] - 363s 36ms/step - loss: -4746.2764 - accuracy: 0.0130 - val_loss: -4192.2656 - val_accuracy: 0.0129\n",
      "Epoch 6/10\n",
      "10108/10108 [==============================] - 364s 36ms/step - loss: -4746.2764 - accuracy: 0.0130 - val_loss: -4192.2656 - val_accuracy: 0.0129\n",
      "Epoch 7/10\n",
      "10108/10108 [==============================] - 362s 36ms/step - loss: -4746.2764 - accuracy: 0.0130 - val_loss: -4192.2656 - val_accuracy: 0.0129\n",
      "Epoch 8/10\n",
      "10108/10108 [==============================] - 364s 36ms/step - loss: -4746.2764 - accuracy: 0.0130 - val_loss: -4192.2656 - val_accuracy: 0.0129\n",
      "Epoch 9/10\n",
      "10108/10108 [==============================] - 362s 36ms/step - loss: -4746.2764 - accuracy: 0.0130 - val_loss: -4192.2656 - val_accuracy: 0.0129\n",
      "Epoch 10/10\n",
      "10108/10108 [==============================] - 377s 37ms/step - loss: -4746.2764 - accuracy: 0.0130 - val_loss: -4192.2656 - val_accuracy: 0.0129\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/maxh/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/maxh/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/maxh/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/maxh/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/home/maxh/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/maxh/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_2\" (type Sequential).\n    \n    Input 0 of layer \"simple_rnn_2\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 32)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=string)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mload_model(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./models/rnn.h5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#test_results = model.evaluate(train_data)\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#print(f'Test acc : {test_results}')\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m#if not os.path.exists('models'):\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#    os.mkdir('models')\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m test \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWhat is the step by step guide to invest in share market in india?\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWhat is the step by step guide to invest in share market?\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(test)\n",
      "File \u001B[0;32m~/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1147\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1147\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[1;32m   1148\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/home/maxh/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/maxh/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/maxh/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/maxh/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/home/maxh/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/maxh/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_2\" (type Sequential).\n    \n    Input 0 of layer \"simple_rnn_2\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 32)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=string)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model = tf.keras.models.load_model('./models/rnn.h5')\n",
    "test_results = model.evaluate(train_data)\n",
    "print(f'Test acc : {test_results}')\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "\n",
    "\n",
    "model.save('models/rnn.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          3179360   \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, None, 32)          2080      \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,183,553\n",
      "Trainable params: 3,183,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer \"sequential_2\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor: shape=(32, 29), dtype=int64, numpy=\narray([[  1,   2,   3,   4,   5,   4,   6,   7,   8,   9,  10,  11,   9,\n         12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,   2,   3,  13,  14,  15,  16,  17,  18,  19,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  29,  30,  31,   3,  32,  14,  33,  34,  35,  36,  37,  38,\n         39,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 46,  47,  30,  48,  49,  50,  28,  29,  30,  51,  52,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 60,  61,  62,   9,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 74,  30,  47,  38,  75,  76,  77,  78,  68,  79,  80,  81,  82,\n         83,  84,  85,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 92,  30,  93,  94,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  29,  30,  41,  38, 103, 104,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [108, 106, 109, 110, 111, 112,  14, 113,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [114, 115, 116,  30, 117,  33, 118, 119, 120,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [123,   7, 124, 125,  14, 126,  37, 127, 128,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 106,  30, 139,  68, 124,  33, 140, 141,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  29, 145, 146, 147,   7, 148,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 150, 151, 152, 153, 154, 155,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129,   3, 156,   7, 157, 151, 158,  99,  38, 159, 160,   7,\n         38, 161, 162,   9,   3, 163, 164, 106, 165, 166,   7,   3, 167,\n        156,   9, 168],\n       [  1,  20,  38, 170, 171, 172, 121, 173, 174, 175, 176, 177, 178,\n        179, 180, 160,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  82, 187, 172,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 46, 106, 189, 190,   7,  41, 191, 192,   3, 193, 165, 194,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 46, 129, 200, 201, 202, 203, 204, 205,  83, 129, 206, 207, 178,\n        208,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 60,   2,   3, 213, 214, 215, 216,   9, 217,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 46, 106, 220, 221, 222,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 176, 225, 226,   7,  41, 227,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129,   3, 205, 105, 230, 210, 178, 202,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 232,   2, 233, 234,   9, 235,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  82,  52, 172,  83, 241, 242,  30, 221, 243,   3, 244,   3,\n        245, 129,   3, 246,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129, 130, 251, 178, 252,  52,  44,   3, 253, 254, 255, 243,\n        256,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,   2, 259, 260,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [262, 263, 264, 265, 232, 266, 178, 267,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,   2, 213, 269,   7, 145, 270, 271,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 105,  30, 272, 121, 273, 274, 275,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 176,  61, 281, 109,  20, 155,   7, 106, 282,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129, 130, 285, 286, 121, 226, 192,  38, 287,  83, 288, 289,\n        290,   3, 291,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0]])>, <tf.Tensor: shape=(32, 29), dtype=int64, numpy=\narray([[  1,   2,   3,   4,   5,   4,   6,   7,   8,   9,  10,  11,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  20,  21,  22,   3,  23,  24,  25,   3,  15,  16,  17,  18,\n         26,  27,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  29,  40,  32,  41,  42,   5,  43,  44,  45,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 53,   3,  54,  55,  56,  57,  58,  56,   2,  59,   5,  58,  57,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 60,  72,  20,  73,   9,  66,  63,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 30,  87,  38,  88,  75,  76,  89,  68,  90,   9,  75,   1,  82,\n         91,  84,  85,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  95,  96,  97,  68,  98,  99, 100,  68, 101, 102,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 105,  30, 106,   7,  41,  38, 107, 104,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [108, 106, 109, 110, 112,  14,  68,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 106,  30, 117, 114, 120, 121, 122,  34,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129, 130,  14,   3, 131, 132,  29, 133,  85,   3, 134,  68,\n        135,  14, 136,  68, 137, 138,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  29,  30, 142, 143,  33, 144, 141,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  29, 109, 145, 149, 147,   7, 148,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 150, 151, 152, 153, 154,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129,   3, 156,   7, 157, 151, 158,  99,  38, 159, 160,   7,\n         38, 161, 162,   9,   3, 163,  28, 106, 165, 166,   7,   3, 167,\n        156,   9, 169],\n       [ 28, 181,  38, 170, 171, 182,   3, 177, 183,   9, 163, 184, 185,\n          7, 186,   9, 163,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  82, 187, 188,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 106, 195, 196, 197, 198,  38, 199,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 46, 106, 209, 210, 202, 205, 211,  29,  41, 207, 212,   5, 208,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 60,   2,   3, 213, 214, 215, 218,   9, 219,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 46, 129, 220,  68, 223, 224, 222,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  29,  30, 106,   7, 228, 229, 227,  14, 226,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 60, 231, 105,  30, 210, 178, 202,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [236,  29,  30, 124,  38, 237, 238, 121, 239,   7, 240,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 201, 247,  38, 248, 106,  38, 244, 176, 249, 250,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129, 130, 251, 178, 252,  52,  44,   3, 253, 254, 255, 243,\n        257, 258,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,   2,   3, 259, 260, 261,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 106, 267, 268,   7,   3, 263,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,   2, 213, 269,   7, 210, 121, 270, 271,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  61, 105, 276,  83, 277, 278, 279, 272, 121, 273, 274, 280,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 176,  61, 281, 109, 106, 283, 284, 282,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  29,  30, 292,  33, 287,  99, 293, 289, 243, 291,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int64, numpy=\narray([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 1])>]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [45]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m ds_subset \u001B[38;5;241m=\u001B[39m train_data\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m example \u001B[38;5;129;01min\u001B[39;00m ds_subset:\n\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mexample\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/keras/engine/input_spec.py:200\u001B[0m, in \u001B[0;36massert_input_compatibility\u001B[0;34m(input_spec, inputs, layer_name)\u001B[0m\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInputs to a layer should be tensors. Got: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(inputs) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(input_spec):\n\u001B[0;32m--> 200\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLayer \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m expects \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(input_spec)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m input(s),\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    201\u001B[0m                    \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m but it received \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(inputs)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m input tensors. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    202\u001B[0m                    \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInputs received: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minputs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m input_index, (x, spec) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(inputs, input_spec)):\n\u001B[1;32m    204\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: Layer \"sequential_2\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor: shape=(32, 29), dtype=int64, numpy=\narray([[  1,   2,   3,   4,   5,   4,   6,   7,   8,   9,  10,  11,   9,\n         12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,   2,   3,  13,  14,  15,  16,  17,  18,  19,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  29,  30,  31,   3,  32,  14,  33,  34,  35,  36,  37,  38,\n         39,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 46,  47,  30,  48,  49,  50,  28,  29,  30,  51,  52,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 60,  61,  62,   9,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 74,  30,  47,  38,  75,  76,  77,  78,  68,  79,  80,  81,  82,\n         83,  84,  85,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 92,  30,  93,  94,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  29,  30,  41,  38, 103, 104,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [108, 106, 109, 110, 111, 112,  14, 113,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [114, 115, 116,  30, 117,  33, 118, 119, 120,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [123,   7, 124, 125,  14, 126,  37, 127, 128,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 106,  30, 139,  68, 124,  33, 140, 141,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  29, 145, 146, 147,   7, 148,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 150, 151, 152, 153, 154, 155,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129,   3, 156,   7, 157, 151, 158,  99,  38, 159, 160,   7,\n         38, 161, 162,   9,   3, 163, 164, 106, 165, 166,   7,   3, 167,\n        156,   9, 168],\n       [  1,  20,  38, 170, 171, 172, 121, 173, 174, 175, 176, 177, 178,\n        179, 180, 160,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  82, 187, 172,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 46, 106, 189, 190,   7,  41, 191, 192,   3, 193, 165, 194,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 46, 129, 200, 201, 202, 203, 204, 205,  83, 129, 206, 207, 178,\n        208,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 60,   2,   3, 213, 214, 215, 216,   9, 217,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 46, 106, 220, 221, 222,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 176, 225, 226,   7,  41, 227,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129,   3, 205, 105, 230, 210, 178, 202,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 232,   2, 233, 234,   9, 235,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  82,  52, 172,  83, 241, 242,  30, 221, 243,   3, 244,   3,\n        245, 129,   3, 246,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129, 130, 251, 178, 252,  52,  44,   3, 253, 254, 255, 243,\n        256,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,   2, 259, 260,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [262, 263, 264, 265, 232, 266, 178, 267,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,   2, 213, 269,   7, 145, 270, 271,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 105,  30, 272, 121, 273, 274, 275,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 176,  61, 281, 109,  20, 155,   7, 106, 282,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129, 130, 285, 286, 121, 226, 192,  38, 287,  83, 288, 289,\n        290,   3, 291,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0]])>, <tf.Tensor: shape=(32, 29), dtype=int64, numpy=\narray([[  1,   2,   3,   4,   5,   4,   6,   7,   8,   9,  10,  11,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  20,  21,  22,   3,  23,  24,  25,   3,  15,  16,  17,  18,\n         26,  27,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  29,  40,  32,  41,  42,   5,  43,  44,  45,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 53,   3,  54,  55,  56,  57,  58,  56,   2,  59,   5,  58,  57,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 60,  72,  20,  73,   9,  66,  63,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 30,  87,  38,  88,  75,  76,  89,  68,  90,   9,  75,   1,  82,\n         91,  84,  85,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  95,  96,  97,  68,  98,  99, 100,  68, 101, 102,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 105,  30, 106,   7,  41,  38, 107, 104,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [108, 106, 109, 110, 112,  14,  68,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 106,  30, 117, 114, 120, 121, 122,  34,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129, 130,  14,   3, 131, 132,  29, 133,  85,   3, 134,  68,\n        135,  14, 136,  68, 137, 138,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  29,  30, 142, 143,  33, 144, 141,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  29, 109, 145, 149, 147,   7, 148,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 150, 151, 152, 153, 154,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129,   3, 156,   7, 157, 151, 158,  99,  38, 159, 160,   7,\n         38, 161, 162,   9,   3, 163,  28, 106, 165, 166,   7,   3, 167,\n        156,   9, 169],\n       [ 28, 181,  38, 170, 171, 182,   3, 177, 183,   9, 163, 184, 185,\n          7, 186,   9, 163,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  82, 187, 188,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 106, 195, 196, 197, 198,  38, 199,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 46, 106, 209, 210, 202, 205, 211,  29,  41, 207, 212,   5, 208,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 60,   2,   3, 213, 214, 215, 218,   9, 219,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 46, 129, 220,  68, 223, 224, 222,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,  29,  30, 106,   7, 228, 229, 227,  14, 226,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 60, 231, 105,  30, 210, 178, 202,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [236,  29,  30, 124,  38, 237, 238, 121, 239,   7, 240,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 201, 247,  38, 248, 106,  38, 244, 176, 249, 250,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 129, 130, 251, 178, 252,  52,  44,   3, 253, 254, 255, 243,\n        257, 258,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,   2,   3, 259, 260, 261,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28, 106, 267, 268,   7,   3, 263,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1,   2, 213, 269,   7, 210, 121, 270, 271,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  61, 105, 276,  83, 277, 278, 279, 272, 121, 273, 274, 280,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [  1, 176,  61, 281, 109, 106, 283, 284, 282,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0],\n       [ 28,  29,  30, 292,  33, 287,  99, 293, 289, 243, 291,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int64, numpy=\narray([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 1])>]"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./models/rnn.h5')\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}