{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Aufgabenstellung\n",
    "\n",
    "Es soll ein Model erstellt werden, welches einem Benutzer bei Eingabe einer Frage ähnliche, bereits vorhanden Fragen vorstellt.\n",
    "Je präsizer der Bentuzer die Frage formuliert, umso präziser sollen auch die Vorhersagen sein."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lösung\n",
    "## Betrachtung des Datensatzes\n",
    "Der Datensatz beinhaltet neben den README-Dateien 3 CSV-Dateien\n",
    "\n",
    "### Trainings-Datensatz\n",
    "Der Trainingsdatensatz ist in der Datei 'training.csv' enthalten.\n",
    "Der Datensatz enthält insgesamt 5 Attribute pro Datum.\n",
    "Eine allgemeine 'id', eine 'qid1' & 'qid2' für die jeweilige Frage.\n",
    "Schlussendlich folgen die beiden Fragen sowie die Spalte 'is_duplicate', bei welcher zwei Fragen mit gleicher Intention mit dem Label 1 markiert sind."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aussortieren nicht benötigter Parameter\n",
    "\n",
    "Die Attribute 'question1', 'question2' und 'is_duplicate' werden auf jedenfall benötigt, da in dieser die Fragen sowie das Klassiefizierungslabel enthalten sind\n",
    "\n",
    "Im zu trainierenden Modell soll rein der textliche Inhalt der Fragen von Bedeutung sein. Aus diesem Grund werden beim Einlesen der Daten die Attribute 'id', 'qid1' & 'qid2' nicht mit geladen.\n",
    "\n",
    "#### Vorverarbeitung der Daten\n",
    "Im geladenen Dataframe werden die Datensätze entfernet, welche in einer der Attribute ein NaN-Value besitzen. Dies ist nötig, da aus diesen Datensätzen keinen sinnvollen Rückschlüsse gezogen werden können.\n",
    "\n",
    "Außerdem werden Duplikate entfernt, da ein Training des selben Datensatzen nicht zur Verbesserung des Modelles beiträgt.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                           question1  \\\n0  What is the step by step guide to invest in sh...   \n1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2  How can I increase the speed of my internet co...   \n3  Why am I mentally very lonely? How can I solve...   \n4  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  \n0  What is the step by step guide to invest in sh...             0  \n1  What would happen if the Indian government sto...             0  \n2  How can Internet speed be increased by hacking...             0  \n3  Find the remainder when [math]23^{24}[/math] i...             0  \n4            Which fish would survive in salt water?             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/nkaps98/quora-question-pairs-glove-lstm\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Multiply, Flatten, Dropout, Dense, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.random.set_seed(35)\n",
    "\n",
    "df_train = pd.read_csv(\n",
    "    \"./fragen/train.csv\",\n",
    "    usecols = ['question1', 'question2', 'is_duplicate'],\n",
    "    encoding = 'utf-8'\n",
    ")\n",
    "\n",
    "df_train.dropna(inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Damit der Text präziser verarbeitet werden kann, werden außerdem alle Buchstaben in lowercase umgewandelt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_train = df_train.applymap(lambda s: s.lower() if type(s) == str else s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualisieren der Trainingsdaten\n",
    "#### Verteilung der Labels in den Trainingsdaten\n",
    "\n",
    "Im folgenden wird die Verteilung der Label in den Trainingsdaten mit Hilfe eines Balkendiagrammes visualisiert."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Number of elements found in dataset')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "label_dist = df_train.is_duplicate.value_counts()\n",
    "\n",
    "ax.bar([0,1],label_dist)\n",
    "ax.set_xticks([0,1], labels=[0,1])\n",
    "ax.set_title('Number of elements found in dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Anzahl der Duplikate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                question1  \\\n0                  can i pay with a debit card on paypal?   \n1         does new york state have a flagship university?   \n2        failures haunt me all the time.how do i cope up?   \n3        how do i make the time lapse images using an ...   \n4        i didn't file a police report for a car accid...   \n...                                                   ...   \n403941      你说我说中文会不会有人看得懂. what does this sentence mean?   \n403942                                格局how to translate?   \n403943                                格局how to translate?   \n403944  黎权锋, help me make up an english name, thank yo...   \n403945         what do you usually do with the internet?   \n\n                                                question2  is_duplicate  size  \n0       can you transfer paypal funds onto a debit car...             0     1  \n1                    how can the new york state be fixed?             0     1  \n2               what can help me cope up with my failure?             1     1  \n3                   how do i make time-lapse photography?             0     1  \n4       why don't i get the money i paid for a year wo...             0     1  \n...                                                   ...           ...   ...  \n403941                      what does this sentence mean?             0     1  \n403942                         how do you translate this?             0     1  \n403943                     how would you translate \"一百回\"?             0     1  \n403944  would you want to help me come up with a name ...             0     1  \n403945          what do you usually do with the internet?             1     1  \n\n[403946 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n      <th>size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>can i pay with a debit card on paypal?</td>\n      <td>can you transfer paypal funds onto a debit car...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>does new york state have a flagship university?</td>\n      <td>how can the new york state be fixed?</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>failures haunt me all the time.how do i cope up?</td>\n      <td>what can help me cope up with my failure?</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>how do i make the time lapse images using an ...</td>\n      <td>how do i make time-lapse photography?</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i didn't file a police report for a car accid...</td>\n      <td>why don't i get the money i paid for a year wo...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>403941</th>\n      <td>你说我说中文会不会有人看得懂. what does this sentence mean?</td>\n      <td>what does this sentence mean?</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>403942</th>\n      <td>格局how to translate?</td>\n      <td>how do you translate this?</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>403943</th>\n      <td>格局how to translate?</td>\n      <td>how would you translate \"一百回\"?</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>403944</th>\n      <td>黎权锋, help me make up an english name, thank yo...</td>\n      <td>would you want to help me come up with a name ...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>403945</th>\n      <td>what do you usually do with the internet?</td>\n      <td>what do you usually do with the internet?</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>403946 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.duplicated(keep='first').sum())\n",
    "df_train.groupby(df_train.columns.tolist(),as_index=False).size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "105761"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dist[0] - label_dist[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Es lässt sich beobachten, das circa 106k mehr Fragen mit dem Label 0, also sinnlich nicht verwandt, versehen sind. Dies kann bei dem trainierten Modell dazu führen, dass das Model zuverlässiger bei der Erkennung von nicht gleichen Fragen als bei gleichen Fragen ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Einlesen der Testdaten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12505/1888995335.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_data_raw = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/plain": "   test_id  is_duplicate\n0        0             1\n1        1             1\n2        2             1\n3        3             1\n4        4             1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test_id</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_raw = pd.read_csv(\n",
    "    \"./fragen/test.csv\",\n",
    "    usecols= ['test_id', 'question1', 'question2'],\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "test_data_raw = test_data_raw.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "test_data_raw.dropna(inplace=True)\n",
    "test_data_raw.head()\n",
    "\n",
    "submission_data_raw = pd.read_csv(\n",
    "    \"./fragen/sample_submission.csv\",\n",
    "    usecols = ['test_id', 'is_duplicate']\n",
    ")\n",
    "\n",
    "submission_data_raw.dropna(inplace=True)\n",
    "submission_data_raw.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Zusammenführen der beiden Dataframes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "1    2345790\nName: is_duplicate, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_merged_raw = test_data_raw.merge(submission_data_raw, left_on=\"test_id\", right_on=\"test_id\")\n",
    "\n",
    "test_data_merged_raw.dropna(inplace=True)\n",
    "test_data_merged_raw.drop_duplicates(inplace=True)\n",
    "test_data_merged_raw.head()\n",
    "\n",
    "test_data_merged_raw.is_duplicate.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kodieren der Fragen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "target_test = test_data_merged_raw.pop('is_duplicate')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aufteilung der Trainingsdaten in Trainings- und Validierungsdaten\n",
    "Vom Trainingsdatensatz wird die Label-Spalte 'is_duplicate' abgespaltet\n",
    "\n",
    "Der Trainingsdatensatz wird in Trainings- und Validierungsdaten aufgeteilt.\n",
    "\n",
    "20% des Trainingsdatensatzes werden als Validierungsdatensatz abgespalten.\n",
    "\n",
    "Für ein reproduzierbares Ergebnis wurden bei der Aufteilung des Datensatzes ein festgelegter Seed verwendet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                question1  \\\n283108  which are the best german universities for an ...   \n73636                         i like being merchant navy?   \n46418   what is the legal definition of a human being?...   \n11449   how can i handle having personal issues with m...   \n283432  how cold can the gobi desert get, and how do i...   \n\n                                                question2  \n283108  which are the best german universities for an ...  \n73636      are astronauts allowed to masturbate in space?  \n46418            what do men think about menstrual cycle?  \n11449   how do i take things my partner says less pers...  \n283432  how cold can the gobi desert get, and how do i...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>283108</th>\n      <td>which are the best german universities for an ...</td>\n      <td>which are the best german universities for an ...</td>\n    </tr>\n    <tr>\n      <th>73636</th>\n      <td>i like being merchant navy?</td>\n      <td>are astronauts allowed to masturbate in space?</td>\n    </tr>\n    <tr>\n      <th>46418</th>\n      <td>what is the legal definition of a human being?...</td>\n      <td>what do men think about menstrual cycle?</td>\n    </tr>\n    <tr>\n      <th>11449</th>\n      <td>how can i handle having personal issues with m...</td>\n      <td>how do i take things my partner says less pers...</td>\n    </tr>\n    <tr>\n      <th>283432</th>\n      <td>how cold can the gobi desert get, and how do i...</td>\n      <td>how cold can the gobi desert get, and how do i...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df_train.pop('is_duplicate')\n",
    "\n",
    "xTrain, xValid, yTrain, yValid = train_test_split(df_train, target, test_size=0.2, random_state=35)\n",
    "xTrain.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Erstellung eines Tokenizers\n",
    "\n",
    "Um ein besseres Training zu ermöglichen, wird ein Tokenizer erstellt, welche die Wörter der Fragen einem Integer-Value zuordnet.\n",
    "Der Tokenizer wird auf alle Fragen des nicht gesplitteten Trainingsdatensatzes angewandt."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(df_train.question1.values) + list(df_train.question2.values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kodierung  und Anpassung der Form der Fragen\n",
    "Die Fragen der gesplitteten Datensätzen werden mittels des erstellten Tokenizer kodiert, sprich der String zu einem Array aus Integer werden umgewandelt.\n",
    "\n",
    "Damit die Fragen auch alle das gleiche Format besitzen, wird das Array anschließend auf eine Länge von 40 gestreckt.\n",
    "\n",
    "Positionen, welche nicht durch die Interger-Werte der Wörter des vorherigen Stringes gefüllt wurden, werden mit dem Wert 0 gefüllt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def tokenizeQuestions(df_questions):\n",
    "    tokenized_questions = tokenizer.texts_to_sequences(df_questions)\n",
    "    return pad_sequences(tokenized_questions, maxlen = 36, padding = 'post')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "q1_train = tokenizeQuestions(xTrain.question1)\n",
    "q2_train = tokenizeQuestions(xTrain.question2)\n",
    "\n",
    "q1_valid = tokenizeQuestions(xValid.question1)\n",
    "q2_valid = tokenizeQuestions(xValid.question2)\n",
    "\n",
    "q1_test = tokenizeQuestions(test_data_merged_raw.question1)\n",
    "q2_test = tokenizeQuestions(test_data_merged_raw.question2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Erstellung eines Dictionaries, welche später für das Finden von ähnlichen Fragen verwendet wird"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ...     0     0     0]\n",
      " [    1    18    10 ...     0     0     0]\n",
      " [    1    18    10 ...     0     0     0]\n",
      " ...\n",
      " [95102     9     5 ...     0     0     0]\n",
      " [95184    99     7 ...     0     0     0]\n",
      " [95457 11220  5907 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "completeQuestionsDict = np.unique(np.concatenate((q1_train, q2_train, q1_valid, q2_valid)), axis=0)\n",
    "print(completeQuestionsDict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Erstellung des Modelles\n",
    "Das Model beinhaltet 2 Untermodelle. Die Outputs dieser Modellen werden im Lauf des Modelles zusammengefügt und weiter verarbeitet.\n",
    "\n",
    "Die 2 Untermodelle werden benötigt, da die 2 verschiedenen Fragen 2 Modell-Inputs darstellen und jeweils entsprechend (vor)verarbeitet werden müssen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Erstellung einem vorgefertigeten GloVe Model für das Embedding-Layer\n",
    "Bei der Aufgabenstellung bietet es sich an, für die Gewichtung des Embedding-Layers ein vorgefertigtes Modell zu nehmen.\n",
    "In dieser Ausführung wird dazu das GloVe-Modell der Standard-Univerity verwendet.\n",
    "Es enthält 42B-Tokens, und einen Umfang von 1.9M Wörtern\n",
    "https://github.com/stanfordnlp/GloVe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Erstellung der Input-Modelle\n",
    "Da die beiden Untermodelle einen identischen Aufbau besitzen, wurde zur Erstellung dieser eine entsprechende Funktion erstellt\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#embeddings = {}\n",
    "#with open('./glove/glove.42B.300d.txt', encoding='utf-8') as f:\n",
    "#    for line in f:\n",
    "#        values = line.split(' ')\n",
    "#        embeddings[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "#    f.close()\n",
    "#print(f'Length of word embedding: {len(embeddings)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#weight_matrix = np.zeros((len(word_index)+1, 300))\n",
    "#for word, i in word_index.items():\n",
    "#    if embeddings.get(word) is not None:\n",
    "#        weight_matrix[i] = embeddings.get(word)\n",
    "#print('Null word embeddings: %d' % np.sum(np.sum(weight_matrix, axis=1) == 0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def createInputModel(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    #hp_learning_rate = hp.Choice('weights', values=[True, False])\n",
    "    #if hp_learning_rate:\n",
    "    #    model.add(Embedding(len(word_index)+1, output_dim = 300, input_length = 36, weights=[weight_matrix]))\n",
    "    #else:\n",
    "    model.add(Embedding(len(word_index)+1, output_dim = 300, input_length = 36))\n",
    "    model.add(LSTM(128, return_sequences = True))\n",
    "    model.add(LSTM(128))\n",
    "    hp_units = hp.Int('units', min_value = 8, max_value = 32, step = 4)\n",
    "    model.add(Dense(units=hp_units, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merging the input of the two models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def createFinalModel(hp):\n",
    "    q1_model = createInputModel(hp)\n",
    "    q2_model = createInputModel(hp)\n",
    "    mergedInputs = Multiply()([q1_model.output, q2_model.output])\n",
    "    mergedInputs = Flatten()(mergedInputs)\n",
    "    hp_units = hp.Int('units', min_value=100, max_value=150, step=10)\n",
    "    mergedInputs = Dense(units=hp_units, activation = 'relu')(mergedInputs)\n",
    "    mergedInputs = Dropout(0.2)(mergedInputs)\n",
    "    hp_units = hp.Int('units', min_value=50, max_value=100, step=10)\n",
    "    mergedInputs = Dense(units=hp_units, activation = 'relu')(mergedInputs)\n",
    "    mergedInputs = Dropout(0.2)(mergedInputs)\n",
    "    mergedInputs = Dense(1, activation = 'sigmoid')(mergedInputs)\n",
    "    model = tf.keras.Model(inputs = [q1_model.input, q2_model.input], outputs = mergedInputs)\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project optimizer/g_optimizer/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from optimizer/g_optimizer/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(createFinalModel,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='optimizer',\n",
    "                     project_name='g_optimizer')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compile and fit the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "<keras_tuner.engine.hyperparameters.HyperParameters object at 0x7f9fbcfc6a60>\n"
     ]
    }
   ],
   "source": [
    "history = tuner.search([q1_train, q2_train], yTrain,\n",
    "                    validation_data = ((q1_valid, q2_valid), yValid),\n",
    "                    epochs = 20,\n",
    "                    batch_size = 2048,\n",
    "                    callbacks=[stop_early]\n",
    ")\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kreation des besten Modelles und Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "158/158 [==============================] - 38s 205ms/step - loss: 0.6442 - accuracy: 0.6405 - val_loss: 0.5708 - val_accuracy: 0.7147\n",
      "Epoch 2/5\n",
      "158/158 [==============================] - 31s 196ms/step - loss: 0.5388 - accuracy: 0.7333 - val_loss: 0.5236 - val_accuracy: 0.7430\n",
      "Epoch 3/5\n",
      "158/158 [==============================] - 32s 202ms/step - loss: 0.4923 - accuracy: 0.7599 - val_loss: 0.5148 - val_accuracy: 0.7502\n",
      "Epoch 4/5\n",
      "158/158 [==============================] - 31s 194ms/step - loss: 0.4558 - accuracy: 0.7791 - val_loss: 0.5123 - val_accuracy: 0.7547\n",
      "Epoch 5/5\n",
      "158/158 [==============================] - 33s 210ms/step - loss: 0.4261 - accuracy: 0.7931 - val_loss: 0.5264 - val_accuracy: 0.7559\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit([q1_train, q2_train], yTrain,\n",
    "                    validation_data = ((q1_valid, q2_valid), yValid),\n",
    "                    epochs = 5,\n",
    "                    batch_size = 2048\n",
    ")\n",
    "\n",
    "#val_acc_per_epoch = history.history['val_accuracy']\n",
    "#best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Erneutes Bauen Fitting mit der optimalen Epochen-Anzahl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "#hypermodel = tuner.hypermodel.build(best_hps)\n",
    "#history = hypermodel.fit([q1_train, q2_train], yTrain,\n",
    "#                    validation_data = ((q1_valid, q2_valid), yValid),\n",
    "#                    epochs = best_epoch,\n",
    "#                    batch_size = 2048\n",
    "#)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validierung\n",
    "In der folgenden Funktion wird die genauigkeit des Modelles bestimmt.\n",
    "Die Bestimmung der Genauigkeit erfolgt auf das Trainingsdatenset, das Validierungsdatenset als auch das Testdatenset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 8s 52ms/step - loss: 0.3925 - accuracy: 0.8085\n",
      "Trainings acc: 0.8085298538208008\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.5264 - accuracy: 0.7559\n",
      "Validation acc: 0.7559177875518799\n",
      "1146/1146 [==============================] - 63s 55ms/step - loss: 1.8344 - accuracy: 0.2035\n",
      "Test acc : 0.2034623771905899\n"
     ]
    }
   ],
   "source": [
    "def evaluteModel(model, training, valid, test):\n",
    "    trainings_eval = model.evaluate([q1_train, q2_train], yTrain, batch_size=2048)\n",
    "    print(f'Trainings acc: {trainings_eval[1]}')\n",
    "    valid_eval = model.evaluate([q1_valid, q2_valid], yValid, batch_size=2048)\n",
    "    print(f'Validation acc: {valid_eval[1]}')\n",
    "    test_results = model.evaluate([q1_test, q2_test], target_test, batch_size=2048)\n",
    "    print(f'Test acc : {test_results[1]}')\n",
    "\n",
    "evaluteModel(model,[q1_train, q2_train], [q1_valid, q2_valid], [q1_test, q2_test])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Erstellung eines Modeles mit einem vorgefertigeten GloVe Model für das Embedding-Layer\n",
    "Bei der Aufgabenstellung bietet es sich an, für die Gewichtung des Embedding-Layers ein vorgefertigtes Modell zu nehmen.\n",
    "In dieser Ausführung wird dazu das GloVe-Modell der Standard-Univerity verwendet.\n",
    "Es enthält 42B-Tokens, und einen Umfang von 1.9M Wörtern\n",
    "https://github.com/stanfordnlp/GloVe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Speicherung des Modelles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "\n",
    "model.save('models/kaggle.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [21]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodels\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m      3\u001B[0m     os\u001B[38;5;241m.\u001B[39mmkdir(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodels\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodels/kaggle.h5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Speicherung des gesamten Fragenkataloges\n",
    "Im folgenden wird der komplette Fragenkatalog gespeichert.\n",
    "Dadurch kann dieser in der späteren Webanwendung wieder verwendet werden"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "np.save('models/questions.npy', completeQuestionsDict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Speicherung des Tokenizers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "import json\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open('models/tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Laden des Modells, um ein erneutes Training zu verhindern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 11:00:17.610418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-15 11:00:17.659929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-15 11:00:17.660204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-15 11:00:17.660913: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-15 11:00:17.661570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-15 11:00:17.661815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-15 11:00:17.662020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-15 11:00:18.037357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-15 11:00:18.037559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-15 11:00:18.037720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-15 11:00:18.037852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4721 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 980 Ti, pci bus id: 0000:23:00.0, compute capability: 5.2\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./models/kaggle.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wie aus der gegebenen Accuracy des Test-Datenset hervorgeht, ist diese wesentliche schlechter als noch die Genauigkeit des Trainings- oder Validierungsdatenset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def getPrediction(question1, question2):\n",
    "    test1 = tokenizer.texts_to_sequences(list([question1]))\n",
    "    test1 = pad_sequences(test1, maxlen = 36, padding = 'post')\n",
    "    test2 = tokenizer.texts_to_sequences(list([question2]))\n",
    "    test2 = pad_sequences(test2, maxlen = 36, padding = 'post')\n",
    "    predict = model.predict([test1, test2])\n",
    "    print(predict)\n",
    "    return predict\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5019383]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.5019383]], dtype=float32)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPrediction(\"What was your first sexual experience like?\", \"What was your first sexual experience like?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementierung in ein Frontend\n",
    "## Erstellung einer Funktion, welche aus einer Benutzereingab 3 Fragen vorschlägt\n",
    "Im folgend erfolgt die Definition einer Funktion, welche ähnliche Fragen vorschlägt.\n",
    "Dabei wird neben der Frage des Benutzers das trainierte Model, sowie der Tokenizer und die Sammlung von Fragen aus den Trainingsdaten übergeben"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def getTopThreeQuestions(user_question):\n",
    "    found_questions = []\n",
    "    encoded_user_question = tokenizer.texts_to_sequences([user_question])\n",
    "    encoded_user_question = pad_sequences(encoded_user_question, maxlen = 36, padding = 'post')\n",
    "    something = np.asarray([encoded_user_question[0]]*len(completeQuestionsDict))\n",
    "    test = model.predict([something, completeQuestionsDict], batch_size = 4096, verbose = 1, use_multiprocessing = True)\n",
    "    print(np.sort(test.flatten()))\n",
    "    a = test.flatten()\n",
    "    ind = np.argpartition(a, -5)[-5:]\n",
    "    top3 = ind\n",
    "    print(top3)\n",
    "    for item in top3:\n",
    "        decoded_question = tokenizer.sequences_to_texts([completeQuestionsDict[item]])[0]\n",
    "        found_questions.append(decoded_question)\n",
    "    return found_questions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 11s 82ms/step\n",
      "[0.9984144  0.9984144  0.9984144  ... 0.99841475 0.99841475 0.99841475]\n",
      "[525520 517620 442535 525757 524101]\n",
      "Question 0\n",
      "themselves as true targets and victims of israel without looking at hamas why can they not accept it is a war but instead they said this is a genocide when they have never been in one\n",
      "Question 1\n",
      "computer will your ip address change for example if i lived in the usa but then moved to australia with the same computer will my ip address change or will it still show the usa one\n",
      "Question 2\n",
      "which one is more formal in an e mail using a person's title mr or ms and last name only or using the title with both first and last name when should i use either one\n",
      "Question 3\n",
      "equation math x 2 3x 10 0 math are math alpha math and math beta math where math alpha beta math an equation whose roots are math alpha 1 math and math beta 2 math is\n",
      "Question 4\n",
      "interest laws regarding a vice president's cheney ability to alter the clean water act in a way that enables his company halliburton to profit from the relaxed regulation and what would it take to pass one\n"
     ]
    }
   ],
   "source": [
    "foundQuestions = getTopThreeQuestions(\"What was the significance of the battle of Somme, and how did this battle compare and contrast to the Battle of Rostov?\")\n",
    "for i, question in enumerate(foundQuestions):\n",
    "    print(f\"Question {i}\")\n",
    "    print(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9984145]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.9984145]], dtype=float32)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPrediction(\"What was the significance of the battle of Somme, and how did this battle compare and contrast to the Battle of Rostov?\", \"What was the significance of the battle of Somme, and how did this battle compare and contrast to the Battle of Riyadh?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573/573 [==============================] - 47s 82ms/step\n",
      "(array([0, 1]), array([1868510,  477280]))\n"
     ]
    }
   ],
   "source": [
    "test = model.predict([q1_test, q2_test], batch_size = 4096, verbose = 1, use_multiprocessing = True)\n",
    "bla = np.where(test > 0.5, 1, 0)\n",
    "dist = np.unique(bla, return_counts=True)\n",
    "print(dist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 0 labels in test-data: 0.7965376269828075\n",
      "Percentage of 1 labels in test-data: 0.2034623730171925\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of 0 labels in test-data: {dist[1][0] / len(test.flatten())}\")\n",
    "print(f\"Percentage of 1 labels in test-data: {dist[1][1] / len(test.flatten())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Erstellung eines Webservers\n",
    "Es wurde ein Webserver mit einem einfachen Frontend erstellt. Dieser bekommt ein Frage, und schlägt daraufhin ähnliche Fragen vor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001B[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001B[0m\n",
      "\u001B[2m   Use a production WSGI server instead.\u001B[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 98] Address already in use",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Input \u001B[0;32mIn [73]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m render_template(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquestion_input.html\u001B[39m\u001B[38;5;124m'\u001B[39m, form\u001B[38;5;241m=\u001B[39mform)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m :\n\u001B[0;32m---> 34\u001B[0m     \u001B[43mapp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/flask/app.py:920\u001B[0m, in \u001B[0;36mFlask.run\u001B[0;34m(self, host, port, debug, load_dotenv, **options)\u001B[0m\n\u001B[1;32m    917\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwerkzeug\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mserving\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m run_simple\n\u001B[1;32m    919\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 920\u001B[0m     \u001B[43mrun_simple\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhost\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    921\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    922\u001B[0m     \u001B[38;5;66;03m# reset the first request information if the development server\u001B[39;00m\n\u001B[1;32m    923\u001B[0m     \u001B[38;5;66;03m# reset normally.  This makes it possible to restart the server\u001B[39;00m\n\u001B[1;32m    924\u001B[0m     \u001B[38;5;66;03m# without reloader and that stuff from an interactive shell.\u001B[39;00m\n\u001B[1;32m    925\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_got_first_request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Gruppe_G_Fragen/venv/lib/python3.9/site-packages/werkzeug/serving.py:984\u001B[0m, in \u001B[0;36mrun_simple\u001B[0;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, exclude_patterns, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001B[0m\n\u001B[1;32m    982\u001B[0m s \u001B[38;5;241m=\u001B[39m socket\u001B[38;5;241m.\u001B[39msocket(address_family, socket\u001B[38;5;241m.\u001B[39mSOCK_STREAM)\n\u001B[1;32m    983\u001B[0m s\u001B[38;5;241m.\u001B[39msetsockopt(socket\u001B[38;5;241m.\u001B[39mSOL_SOCKET, socket\u001B[38;5;241m.\u001B[39mSO_REUSEADDR, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 984\u001B[0m \u001B[43ms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbind\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_address\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    985\u001B[0m s\u001B[38;5;241m.\u001B[39mset_inheritable(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    987\u001B[0m \u001B[38;5;66;03m# If we can open the socket by file descriptor, then we can just\u001B[39;00m\n\u001B[1;32m    988\u001B[0m \u001B[38;5;66;03m# reuse this one and our socket will survive the restarts.\u001B[39;00m\n",
      "\u001B[0;31mOSError\u001B[0m: [Errno 98] Address already in use"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}