{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Aufgabenstellung\n",
    "\n",
    "Es soll ein Model erstellt werden, welches einem Benutzer bei Eingabe einer Frage ähnliche, bereits vorhanden Fragen vorstellt.\n",
    "Je präsizer der Bentuzer die Frage formuliert, umso präziser sollen auch die Vorhersagen sein."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lösung\n",
    "## Betrachtung des Datensatzes\n",
    "Der Datensatz beinhaltet neben den README-Dateien 3 CSV-Dateien\n",
    "\n",
    "### Trainings-Datensatz\n",
    "Der Trainingsdatensatz ist in der Datei 'training.csv' enthalten.\n",
    "Der Datensatz enthält insgesamt 5 Attribute pro Datum.\n",
    "Eine allgemeine 'id', eine 'qid1' & 'qid2' für die jeweilige Frage.\n",
    "Schlussendlich folgen die beiden Fragen sowie die Spalte 'is_duplicate', bei welcher zwei Fragen mit gleicher Intention mit dem Label 1 markiert sind."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aussortieren nicht benötigter Parameter\n",
    "\n",
    "Die Attribute 'question1', 'question2' und 'is_duplicate' werden auf jedenfall benötigt, da in dieser die Fragen sowie das Klassiefizierungslabel enthalten sind\n",
    "\n",
    "Im zu trainierenden Modell soll rein der textliche Inhalt der Fragen von Bedeutung sein. Aus diesem Grund werden beim Einlesen der Daten die Attribute 'id', 'qid1' & 'qid2' nicht mit geladen.\n",
    "\n",
    "#### Vorverarbeitung der Daten\n",
    "Im geladenen Dataframe werden die Datensätze entfernet, welche in einer der Attribute ein NaN-Value besitzen. Dies ist nötig, da aus diesen Datensätzen keinen sinnvollen Rückschlüsse gezogen werden können.\n",
    "\n",
    "Außerdem werden Duplikate entfernt, da ein Training des selben Datensatzen nicht zur Verbesserung des Modelles beiträgt.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                           question1  \\\n0  What is the step by step guide to invest in sh...   \n1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2  How can I increase the speed of my internet co...   \n3  Why am I mentally very lonely? How can I solve...   \n4  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  \n0  What is the step by step guide to invest in sh...             0  \n1  What would happen if the Indian government sto...             0  \n2  How can Internet speed be increased by hacking...             0  \n3  Find the remainder when [math]23^{24}[/math] i...             0  \n4            Which fish would survive in salt water?             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/nkaps98/quora-question-pairs-glove-lstm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Multiply, Flatten, Dropout, Dense, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.random.set_seed(35)\n",
    "\n",
    "df_train = pd.read_csv(\n",
    "    \"./fragen/train.csv\",\n",
    "    usecols = ['question1', 'question2', 'is_duplicate'],\n",
    "    encoding = 'utf-8'\n",
    ")\n",
    "\n",
    "df_train.dropna(inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Damit der Text präziser verarbeitet werden kann, werden außerdem alle Buchstaben in lowercase umgewandelt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_train = df_train.applymap(lambda s: s.lower() if type(s) == str else s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualisieren der Trainingsdaten\n",
    "#### Verteilung der Labels in den Trainingsdaten\n",
    "\n",
    "Im folgenden wird die Verteilung der Label in den Trainingsdaten mit Hilfe eines Balkendiagrammes visualisiert."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Number of elements found in dataset')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAW/UlEQVR4nO3de7RedX3n8ffHIEq5CEjKAEkJS6MVnSlqBujodKhMIeCaFbrGC0yVFBGs4lLX1BnRuWBVqnZaWTJVLA4ZoFaRURkzFZumqLWOogRruYiUMwhNMEAgXMVLwe/88fyCO4fnd3JyOych79dazzr7+e7f3r/fs88+z+fsy3lOqgpJksZ5ymwPQJK04zIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUioK8nFSd43S30nyf9Mcl+Sb23B8pXk2dtjbLNha7fHVvb97iSf6Mz7l0lu3kb9LGjft922xfq0bRgSO5EktyW5O8meg9rrk3xlFoe1vbwU+A1gXlUdOduD2RamerOdhh1ye1TV31TVc2e63yTHJFnzZOlnR2ZI7HzmAG+d7UFsriRzNnORQ4HbquqH22M8OyG3h2aFIbHz+W/A25PsO3nGuMP1JF9J8vo2/dtJ/m+S85Lcn+TWJP+i1Ve3o5Slk1Z7QJKVSR5K8tdJDh2s+5fbvPVJbk7yqsG8i5NckOTKJD8Efn3MeA9OsrwtP5HkjFY/HfgfwK8meTjJ743bEElel+SmdgpmxXBsk9o9LckfJvmHJHcl+ViSPdq8Y5KsSfIf2+tfm+SkJCcm+fs2tncN1vWUJGcn+X9J7k1yeZL9J23/pa2ve5L8pzZvMfAu4NXtNf3d4Htya9u+30/yW2PGP3Z7JDmjbbf1bTsevBn7wdfaNrmv9XvCoO1h7Xv9UJKVwAHjtutw+w2e35bk7UmuS/JAkk8neXpn2TltDPckuRV4+aT5p7Xv70NtG72h1fcEvggc3LbHw21fOjLJN9q+vTbJHyfZvS2TjPb7u5M8mOT6JC+Yav/o9dPbFk9aVeVjJ3kAtwH/Gvgc8L5Wez3wlTa9AChgt8EyXwFe36Z/G3gUOI3REcn7gH8APgI8DTgOeAjYq7W/uD3/tTb/w8DX2rw9gdVtXbsBLwTuAQ4fLPsA8BJGv4w8fczr+SrwUeDpwBHAOuBlg7F+bYptsQSYAJ7X+v/PwNcH8wt4dps+D1gO7A/sDfwf4P1t3jFtm/xX4KnAGW0cn2xtnw/8CDistX8rcDUwr22TPwE+NWn7fxzYA/gV4CfA89r8dwOfGIxxT+BB4Lnt+UHA8zuvd6PtAbysbe8XtXH8d+Crm7Ef/GN7rXOANwI/ANLmfwP4UFvvr7V94BOdcR0DrJm0j34LOLht75uA3+ks+zvA94D5re2Xh+NmFBrPAgL8K+AR4EXj+m21FwNHt/1hQev7bW3e8cC1wL5tfc8DDprm/rFm3Ph3lcesD8DHZnyzfh4SL2D0BjyXzQ+JWwbz/mlrf+Cgdi9wRJu+GLhsMG8v4LH2Q/1q4G8mje9PgHMGy146xWuZ39a196D2fuDiwVinCokvAqcPnj+lvYkc2p4X8Oz2hvBD4FmDtr8KfL9NH8MoBOa053u3ZY8atL8WOKlN3wQcO5h3EKM33A1vTMXousGG+d8CTm7T7+aJIXE/8G+BPTbxvd9oewAXAX8w6Xvzj20M09kPJgbzfqG1/yfALzEKzT0H8z/J5oXEawbP/wD4WGfZLzEIEEa/pGw07knt/zfw1nH9dtq/DbiiTb8M+HtGIfKUQZvp7B+7dEh4umknVFU3AH8OnL0Fi981mP5RW9/k2l6D56sH/T4MrGf0W+KhwFHt0P7+JPcDv8XojeYJy45xMLC+qh4a1G4HDpnm6zgU+PCg7/WMfuAnLz+X0ZvgtYO2f9HqG9xbVY+16R+1r71tcihwxWBdNzEKuwMH7e8cTD/CxtvzcTW6vvBqRr9Rr03yhSS/PNWLHjiY0fbasK6HGQX8dLff42Osqkfa5F5tvffVxtc+bmfzTOv1t76G+8hG/SQ5IcnV7XTa/cCJTH3q6zlJ/jzJnUkeBH5/Q/uq+hLwx4yOmu9OcmGSfZje/rFLMyR2XucwOl0wfFPY8IP9C4Pa8E17S8zfMJFkL0aH5D9g9MP911W17+CxV1W9cbDsVB8x/ANg/yR7D2q/BNwxzXGtBt4wqf89qurrk9rdw+hN/vmDds+oqt4b13T6PWFSv0+vqumM+wnbo6pWVNVvMDoi+R6jU1XT8QNGgQU8fp7+mYy239bsB2uB/TK4g47R92V7WMtg/xr2k+RpwGeBP2R0pLsvcCWjXwRg/L51AaNtuLCq9mF0DWhDe6rq/Kp6MXA48BzgP7Dp/WOX/5hsQ2InVVUTwKeBtwxq6xi9SbymXRR8HaNzulvjxCQvbRcA3wtcXVWrGR3JPCfJa5M8tT3+eZLnTXP8q4GvA+9P8vQk/ww4HZjuLaIfA96Z5PkASZ6R5JVj+vkZozfe85L8Ymt7SJLjp9nPuH7PTbtInmRukiXTXPYuYEGSp7RlD0yypL0h/wR4GPjZNNf1KeC0JEe0N9TfB75ZVbdtzX5QVbcDq4DfS7J7kpcC/2aaY9pclwNvSTIvyX5sfGS8O6NrIuuAR9uF9eMG8+8CnpnkGYPa3oyu8Tzcjsge/4Wl7ZtHJXkqoxD9MfCzaewf4/rZpRgSO7f3MDqvPXQGo9+Q7mV00XXyb9ab65OMjlrWM7ow+BqAdproOOBkRr/V3gl8kNEP9nSdwuj8+Q+AKxhdz/ir6SxYVVe0/i5rpxZuAE7oNH8Ho4vcV7e2fwVs6b39H2Z0kfMvkzzE6CL2UdNc9n+1r/cm+Tajn79/z+j1r2d0cfaNnWU30rbTf2H02/ZaRiFw8qDJ1uwH/47Ra1rP6Ht/6WYsuzk+DqwA/g74NqMbMoDH96+3MAqS+9qYlg/mf49RUN7aThMdDLy9tXuorfvTg772abX7GJ3WupfRnYIwxf7R6WeXsuFuBkmSnsAjCUlSlyEhSeoyJCRJXYaEJKnrSfeRvAcccEAtWLBgtochSTuVa6+99p6qesIfET7pQmLBggWsWrVqtochSTuVJGP/st7TTZKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpK4n3V9cb40FZ39htoegHdRtH3j5bA9BmhWbPJJIMj/Jl5N8N8mNSd7a6u9OckeS77THiYNl3plkIsnNw38TmWRxq00kOXtQPyzJN1v90+1fZZLkae35RJu/YJu+eknSlKZzuulR4Her6nDgaOCsJIe3eedV1RHtcSVAm3cyo3+ZuBj4aPs/u3OAjzD6F5OHA6cM1vPBtq5nM/r3gqe3+unAfa1+XmsnSZohmwyJqlpbVd9u0w8BNwGHTLHIEuCyqvpJVX2f0f+OPbI9Jqrq1qr6KXAZsCRJgJcBn2nLXwKcNFjXJW36M8Cxrb0kaQZs1oXrdrrnhcA3W+nNSa5LsizJfq12CLB6sNiaVuvVnwncX1WPTqpvtK42/4HWfvK4zkyyKsmqdevWbc5LkiRNYdohkWQv4LPA26rqQeAC4FnAEcBa4I+2xwCno6ourKpFVbVo7twnfBy6JGkLTSskkjyVUUD8WVV9DqCq7qqqx6rqZ8DHGZ1OArgDmD9YfF6r9er3Avsm2W1SfaN1tfnPaO0lSTNgOnc3BbgIuKmqPjSoHzRo9pvADW16OXByuzPpMGAh8C3gGmBhu5Npd0YXt5dXVQFfBl7Rll8KfH6wrqVt+hXAl1p7SdIMmM7fSbwEeC1wfZLvtNq7GN2ddARQwG3AGwCq6sYklwPfZXRn1FlV9RhAkjcDK4A5wLKqurGt7x3AZUneB/wto1Ciff3TJBPAekbBIkmaIZsMiar6GjDujqIrp1jmXODcMfUrxy1XVbfy89NVw/qPgVduaoySpO3Dj+WQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldmwyJJPOTfDnJd5PcmOStrb5/kpVJbmlf92v1JDk/yUSS65K8aLCupa39LUmWDuovTnJ9W+b8JJmqD0nSzJjOkcSjwO9W1eHA0cBZSQ4HzgauqqqFwFXtOcAJwML2OBO4AEZv+MA5wFHAkcA5gzf9C4AzBsstbvVeH5KkGbDJkKiqtVX17Tb9EHATcAiwBLikNbsEOKlNLwEurZGrgX2THAQcD6ysqvVVdR+wEljc5u1TVVdXVQGXTlrXuD4kSTNgs65JJFkAvBD4JnBgVa1ts+4EDmzThwCrB4utabWp6mvG1Jmij8njOjPJqiSr1q1btzkvSZI0hWmHRJK9gM8Cb6uqB4fz2hFAbeOxbWSqPqrqwqpaVFWL5s6duz2HIUm7lGmFRJKnMgqIP6uqz7XyXe1UEe3r3a1+BzB/sPi8VpuqPm9Mfao+JEkzYDp3NwW4CLipqj40mLUc2HCH0lLg84P6qe0up6OBB9opoxXAcUn2axesjwNWtHkPJjm69XXqpHWN60OSNAN2m0ablwCvBa5P8p1WexfwAeDyJKcDtwOvavOuBE4EJoBHgNMAqmp9kvcC17R276mq9W36TcDFwB7AF9uDKfqQJM2ATYZEVX0NSGf2sWPaF3BWZ13LgGVj6quAF4yp3zuuD0nSzPAvriVJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnq2mRIJFmW5O4kNwxq705yR5LvtMeJg3nvTDKR5OYkxw/qi1ttIsnZg/phSb7Z6p9OsnurP609n2jzF2yzVy1JmpbpHElcDCweUz+vqo5ojysBkhwOnAw8vy3z0SRzkswBPgKcABwOnNLaAnywrevZwH3A6a1+OnBfq5/X2kmSZtAmQ6Kqvgqsn+b6lgCXVdVPqur7wARwZHtMVNWtVfVT4DJgSZIALwM+05a/BDhpsK5L2vRngGNbe0nSDNmaaxJvTnJdOx21X6sdAqwetFnTar36M4H7q+rRSfWN1tXmP9DaP0GSM5OsSrJq3bp1W/GSJElDu23hchcA7wWqff0j4HXbalCbq6ouBC4EWLRoUc3WOKTtbcHZX5jtIWgHdtsHXr7N17lFRxJVdVdVPVZVPwM+zuh0EsAdwPxB03mt1qvfC+ybZLdJ9Y3W1eY/o7WXJM2QLQqJJAcNnv4msOHOp+XAye3OpMOAhcC3gGuAhe1Opt0ZXdxeXlUFfBl4RVt+KfD5wbqWtulXAF9q7SVJM2STp5uSfAo4BjggyRrgHOCYJEcwOt10G/AGgKq6McnlwHeBR4Gzquqxtp43AyuAOcCyqrqxdfEO4LIk7wP+Frio1S8C/jTJBKML5ydv7YuVJG2eTYZEVZ0ypnzRmNqG9ucC546pXwlcOaZ+Kz8/XTWs/xh45abGJ0nafvyLa0lSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1LXJkEiyLMndSW4Y1PZPsjLJLe3rfq2eJOcnmUhyXZIXDZZZ2trfkmTpoP7iJNe3Zc5Pkqn6kCTNnOkcSVwMLJ5UOxu4qqoWAle15wAnAAvb40zgAhi94QPnAEcBRwLnDN70LwDOGCy3eBN9SJJmyCZDoqq+CqyfVF4CXNKmLwFOGtQvrZGrgX2THAQcD6ysqvVVdR+wEljc5u1TVVdXVQGXTlrXuD4kSTNkS69JHFhVa9v0ncCBbfoQYPWg3ZpWm6q+Zkx9qj4kSTNkqy9ctyOA2gZj2eI+kpyZZFWSVevWrdueQ5GkXcqWhsRd7VQR7evdrX4HMH/Qbl6rTVWfN6Y+VR9PUFUXVtWiqlo0d+7cLXxJkqTJtjQklgMb7lBaCnx+UD+13eV0NPBAO2W0AjguyX7tgvVxwIo278EkR7e7mk6dtK5xfUiSZshum2qQ5FPAMcABSdYwukvpA8DlSU4Hbgde1ZpfCZwITACPAKcBVNX6JO8Frmnt3lNVGy6Gv4nRHVR7AF9sD6boQ5I0QzYZElV1SmfWsWPaFnBWZz3LgGVj6quAF4yp3zuuD0nSzPEvriVJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnq2qqQSHJbkuuTfCfJqlbbP8nKJLe0r/u1epKcn2QiyXVJXjRYz9LW/pYkSwf1F7f1T7RlszXjlSRtnm1xJPHrVXVEVS1qz88GrqqqhcBV7TnACcDC9jgTuABGoQKcAxwFHAmcsyFYWpszBsst3gbjlSRN0/Y43bQEuKRNXwKcNKhfWiNXA/smOQg4HlhZVeur6j5gJbC4zdunqq6uqgIuHaxLkjQDtjYkCvjLJNcmObPVDqyqtW36TuDANn0IsHqw7JpWm6q+Zkz9CZKcmWRVklXr1q3bmtcjSRrYbSuXf2lV3ZHkF4GVSb43nFlVlaS2so9NqqoLgQsBFi1atN37k6RdxVYdSVTVHe3r3cAVjK4p3NVOFdG+3t2a3wHMHyw+r9Wmqs8bU5ckzZAtDokkeybZe8M0cBxwA7Ac2HCH0lLg8216OXBqu8vpaOCBdlpqBXBckv3aBevjgBVt3oNJjm53NZ06WJckaQZszemmA4Er2l2puwGfrKq/SHINcHmS04HbgVe19lcCJwITwCPAaQBVtT7Je4FrWrv3VNX6Nv0m4GJgD+CL7SFJmiFbHBJVdSvwK2Pq9wLHjqkXcFZnXcuAZWPqq4AXbOkYJUlbx7+4liR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKlrhw+JJIuT3JxkIsnZsz0eSdqV7NAhkWQO8BHgBOBw4JQkh8/uqCRp17FDhwRwJDBRVbdW1U+By4AlszwmSdpl7DbbA9iEQ4DVg+drgKMmN0pyJnBme/pwkptnYGy7ggOAe2Z7EDuCfHC2R6AO99GBrdxPDx1X3NFDYlqq6kLgwtkex5NNklVVtWi2xyH1uI9ufzv66aY7gPmD5/NaTZI0A3b0kLgGWJjksCS7AycDy2d5TJK0y9ihTzdV1aNJ3gysAOYAy6rqxlke1q7EU3ja0bmPbmepqtkegyRpB7Wjn26SJM0iQ0KS1GVI6An8KBTt6JIsS3J3khtmeyxPdoaENuJHoWgncTGweLYHsSswJDSZH4WiHV5VfRVYP9vj2BUYEpps3EehHDJLY5E0ywwJSVKXIaHJ/CgUSY8zJDSZH4Ui6XGGhDZSVY8CGz4K5Sbgcj8KRTuaJJ8CvgE8N8maJKfP9pierPxYDklSl0cSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSp6/8D3xyj8pKMx4UAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "label_dist = df_train.is_duplicate.value_counts()\n",
    "\n",
    "ax.bar([0,1],label_dist)\n",
    "ax.set_xticks([0,1], labels=[0,1])\n",
    "ax.set_title('Number of elements found in dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Anzahl der Duplikate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                question1  \\\n0                  can i pay with a debit card on paypal?   \n1         does new york state have a flagship university?   \n2        failures haunt me all the time.how do i cope up?   \n3        how do i make the time lapse images using an ...   \n4        i didn't file a police report for a car accid...   \n...                                                   ...   \n403941      你说我说中文会不会有人看得懂. what does this sentence mean?   \n403942                                格局how to translate?   \n403943                                格局how to translate?   \n403944  黎权锋, help me make up an english name, thank yo...   \n403945         what do you usually do with the internet?   \n\n                                                question2  is_duplicate  size  \n0       can you transfer paypal funds onto a debit car...             0     1  \n1                    how can the new york state be fixed?             0     1  \n2               what can help me cope up with my failure?             1     1  \n3                   how do i make time-lapse photography?             0     1  \n4       why don't i get the money i paid for a year wo...             0     1  \n...                                                   ...           ...   ...  \n403941                      what does this sentence mean?             0     1  \n403942                         how do you translate this?             0     1  \n403943                     how would you translate \"一百回\"?             0     1  \n403944  would you want to help me come up with a name ...             0     1  \n403945          what do you usually do with the internet?             1     1  \n\n[403946 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n      <th>size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>can i pay with a debit card on paypal?</td>\n      <td>can you transfer paypal funds onto a debit car...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>does new york state have a flagship university?</td>\n      <td>how can the new york state be fixed?</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>failures haunt me all the time.how do i cope up?</td>\n      <td>what can help me cope up with my failure?</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>how do i make the time lapse images using an ...</td>\n      <td>how do i make time-lapse photography?</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i didn't file a police report for a car accid...</td>\n      <td>why don't i get the money i paid for a year wo...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>403941</th>\n      <td>你说我说中文会不会有人看得懂. what does this sentence mean?</td>\n      <td>what does this sentence mean?</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>403942</th>\n      <td>格局how to translate?</td>\n      <td>how do you translate this?</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>403943</th>\n      <td>格局how to translate?</td>\n      <td>how would you translate \"一百回\"?</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>403944</th>\n      <td>黎权锋, help me make up an english name, thank yo...</td>\n      <td>would you want to help me come up with a name ...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>403945</th>\n      <td>what do you usually do with the internet?</td>\n      <td>what do you usually do with the internet?</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>403946 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.duplicated(keep='first').sum())\n",
    "df_train.groupby(df_train.columns.tolist(),as_index=False).size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "105761"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dist[0] - label_dist[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Es lässt sich beobachten, das circa 106k mehr Fragen mit dem Label 0, also sinnlich nicht verwandt, versehen sind. Dies kann bei dem trainierten Modell dazu führen, dass das Model zuverlässiger bei der Erkennung von nicht gleichen Fragen als bei gleichen Fragen ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Einlesen der Testdaten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12505/1888995335.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_data_raw = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/plain": "   test_id  is_duplicate\n0        0             1\n1        1             1\n2        2             1\n3        3             1\n4        4             1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test_id</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_raw = pd.read_csv(\n",
    "    \"./fragen/test.csv\",\n",
    "    usecols= ['test_id', 'question1', 'question2'],\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "test_data_raw = test_data_raw.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "test_data_raw.dropna(inplace=True)\n",
    "test_data_raw.head()\n",
    "\n",
    "submission_data_raw = pd.read_csv(\n",
    "    \"./fragen/sample_submission.csv\",\n",
    "    usecols = ['test_id', 'is_duplicate']\n",
    ")\n",
    "\n",
    "submission_data_raw.dropna(inplace=True)\n",
    "submission_data_raw.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Zusammenführen der beiden Dataframes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "1    2345790\nName: is_duplicate, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_merged_raw = test_data_raw.merge(submission_data_raw, left_on=\"test_id\", right_on=\"test_id\")\n",
    "\n",
    "test_data_merged_raw.dropna(inplace=True)\n",
    "test_data_merged_raw.drop_duplicates(inplace=True)\n",
    "test_data_merged_raw.head()\n",
    "\n",
    "test_data_merged_raw.is_duplicate.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kodieren der Fragen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "target_test = test_data_merged_raw.pop('is_duplicate')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aufteilung der Trainingsdaten in Trainings- und Validierungsdaten\n",
    "Vom Trainingsdatensatz wird die Label-Spalte 'is_duplicate' abgespaltet\n",
    "\n",
    "Der Trainingsdatensatz wird in Trainings- und Validierungsdaten aufgeteilt.\n",
    "\n",
    "20% des Trainingsdatensatzes werden als Validierungsdatensatz abgespalten.\n",
    "\n",
    "Für ein reproduzierbares Ergebnis wurden bei der Aufteilung des Datensatzes ein festgelegter Seed verwendet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                question1  \\\n283108  which are the best german universities for an ...   \n73636                         i like being merchant navy?   \n46418   what is the legal definition of a human being?...   \n11449   how can i handle having personal issues with m...   \n283432  how cold can the gobi desert get, and how do i...   \n\n                                                question2  \n283108  which are the best german universities for an ...  \n73636      are astronauts allowed to masturbate in space?  \n46418            what do men think about menstrual cycle?  \n11449   how do i take things my partner says less pers...  \n283432  how cold can the gobi desert get, and how do i...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>283108</th>\n      <td>which are the best german universities for an ...</td>\n      <td>which are the best german universities for an ...</td>\n    </tr>\n    <tr>\n      <th>73636</th>\n      <td>i like being merchant navy?</td>\n      <td>are astronauts allowed to masturbate in space?</td>\n    </tr>\n    <tr>\n      <th>46418</th>\n      <td>what is the legal definition of a human being?...</td>\n      <td>what do men think about menstrual cycle?</td>\n    </tr>\n    <tr>\n      <th>11449</th>\n      <td>how can i handle having personal issues with m...</td>\n      <td>how do i take things my partner says less pers...</td>\n    </tr>\n    <tr>\n      <th>283432</th>\n      <td>how cold can the gobi desert get, and how do i...</td>\n      <td>how cold can the gobi desert get, and how do i...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df_train.pop('is_duplicate')\n",
    "\n",
    "xTrain, xValid, yTrain, yValid = train_test_split(df_train, target, test_size=0.2, random_state=35)\n",
    "xTrain.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Erstellung eines Tokenizers\n",
    "\n",
    "Um ein besseres Training zu ermöglichen, wird ein Tokenizer erstellt, welche die Wörter der Fragen einem Integer-Value zuordnet.\n",
    "Der Tokenizer wird auf alle Fragen des nicht gesplitteten Trainingsdatensatzes angewandt."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(df_train.question1.values) + list(df_train.question2.values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kodierung  und Anpassung der Form der Fragen\n",
    "Die Fragen der gesplitteten Datensätzen werden mittels des erstellten Tokenizer kodiert, sprich der String zu einem Array aus Integer werden umgewandelt.\n",
    "\n",
    "Damit die Fragen auch alle das gleiche Format besitzen, wird das Array anschließend auf eine Länge von 40 gestreckt.\n",
    "\n",
    "Positionen, welche nicht durch die Interger-Werte der Wörter des vorherigen Stringes gefüllt wurden, werden mit dem Wert 0 gefüllt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def tokenizeQuestions(df_questions):\n",
    "    tokenized_questions = tokenizer.texts_to_sequences(df_questions)\n",
    "    return pad_sequences(tokenized_questions, maxlen = 36, padding = 'post')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "q1_train = tokenizeQuestions(xTrain.question1)\n",
    "q2_train = tokenizeQuestions(xTrain.question2)\n",
    "\n",
    "q1_valid = tokenizeQuestions(xValid.question1)\n",
    "q2_valid = tokenizeQuestions(xValid.question2)\n",
    "\n",
    "q1_test = tokenizeQuestions(test_data_merged_raw.question1)\n",
    "q2_test = tokenizeQuestions(test_data_merged_raw.question2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Erstellung eines Dictionaries, welche später für das Finden von ähnlichen Fragen verwendet wird"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "completeQuestionsDict = np.unique(np.concatenate((q1_train, q2_train, q1_valid, q2_valid)))\n",
    "print(completeQuestionsDict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Erstellung des Modelles\n",
    "Das Model beinhaltet 2 Untermodelle. Die Outputs dieser Modellen werden im Lauf des Modelles zusammengefügt und weiter verarbeitet.\n",
    "\n",
    "Die 2 Untermodelle werden benötigt, da die 2 verschiedenen Fragen 2 Modell-Inputs darstellen und jeweils entsprechend (vor)verarbeitet werden müssen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Erstellung einem vorgefertigeten GloVe Model für das Embedding-Layer\n",
    "Bei der Aufgabenstellung bietet es sich an, für die Gewichtung des Embedding-Layers ein vorgefertigtes Modell zu nehmen.\n",
    "In dieser Ausführung wird dazu das GloVe-Modell der Standard-Univerity verwendet.\n",
    "Es enthält 42B-Tokens, und einen Umfang von 1.9M Wörtern\n",
    "https://github.com/stanfordnlp/GloVe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Erstellung der Input-Modelle\n",
    "Da die beiden Untermodelle einen identischen Aufbau besitzen, wurde zur Erstellung dieser eine entsprechende Funktion erstellt\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#embeddings = {}\n",
    "#with open('./glove/glove.42B.300d.txt', encoding='utf-8') as f:\n",
    "#    for line in f:\n",
    "#        values = line.split(' ')\n",
    "#        embeddings[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "#    f.close()\n",
    "#print(f'Length of word embedding: {len(embeddings)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "#weight_matrix = np.zeros((len(word_index)+1, 300))\n",
    "#for word, i in word_index.items():\n",
    "#    if embeddings.get(word) is not None:\n",
    "#        weight_matrix[i] = embeddings.get(word)\n",
    "#print('Null word embeddings: %d' % np.sum(np.sum(weight_matrix, axis=1) == 0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def createInputModel(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    #hp_learning_rate = hp.Choice('weights', values=[True, False])\n",
    "    #if hp_learning_rate:\n",
    "    #    model.add(Embedding(len(word_index)+1, output_dim = 300, input_length = 36, weights=[weight_matrix]))\n",
    "    #else:\n",
    "    model.add(Embedding(len(word_index)+1, output_dim = 300, input_length = 36))\n",
    "    model.add(LSTM(128, return_sequences = True))\n",
    "    model.add(LSTM(128))\n",
    "    hp_units = hp.Int('units', min_value = 8, max_value = 32, step = 4)\n",
    "    model.add(Dense(units=hp_units, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merging the input of the two models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def createFinalModel(hp):\n",
    "    q1_model = createInputModel(hp)\n",
    "    q2_model = createInputModel(hp)\n",
    "    mergedInputs = Multiply()([q1_model.output, q2_model.output])\n",
    "    mergedInputs = Flatten()(mergedInputs)\n",
    "    hp_units = hp.Int('units', min_value=100, max_value=150, step=10)\n",
    "    mergedInputs = Dense(units=hp_units, activation = 'relu')(mergedInputs)\n",
    "    mergedInputs = Dropout(0.2)(mergedInputs)\n",
    "    hp_units = hp.Int('units', min_value=50, max_value=100, step=10)\n",
    "    mergedInputs = Dense(units=hp_units, activation = 'relu')(mergedInputs)\n",
    "    mergedInputs = Dropout(0.2)(mergedInputs)\n",
    "    mergedInputs = Dense(1, activation = 'sigmoid')(mergedInputs)\n",
    "    model = tf.keras.Model(inputs = [q1_model.input, q2_model.input], outputs = mergedInputs)\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project optimizer/g_optimizer/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from optimizer/g_optimizer/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(createFinalModel,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='optimizer',\n",
    "                     project_name='g_optimizer')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compile and fit the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "<keras_tuner.engine.hyperparameters.HyperParameters object at 0x7f9fbcfc6a60>\n"
     ]
    }
   ],
   "source": [
    "history = tuner.search([q1_train, q2_train], yTrain,\n",
    "                    validation_data = ((q1_valid, q2_valid), yValid),\n",
    "                    epochs = 20,\n",
    "                    batch_size = 2048,\n",
    "                    callbacks=[stop_early]\n",
    ")\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kreation des besten Modelles und Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "158/158 [==============================] - 38s 205ms/step - loss: 0.6442 - accuracy: 0.6405 - val_loss: 0.5708 - val_accuracy: 0.7147\n",
      "Epoch 2/5\n",
      "158/158 [==============================] - 31s 196ms/step - loss: 0.5388 - accuracy: 0.7333 - val_loss: 0.5236 - val_accuracy: 0.7430\n",
      "Epoch 3/5\n",
      "158/158 [==============================] - 32s 202ms/step - loss: 0.4923 - accuracy: 0.7599 - val_loss: 0.5148 - val_accuracy: 0.7502\n",
      "Epoch 4/5\n",
      "158/158 [==============================] - 31s 194ms/step - loss: 0.4558 - accuracy: 0.7791 - val_loss: 0.5123 - val_accuracy: 0.7547\n",
      "Epoch 5/5\n",
      "158/158 [==============================] - 33s 210ms/step - loss: 0.4261 - accuracy: 0.7931 - val_loss: 0.5264 - val_accuracy: 0.7559\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit([q1_train, q2_train], yTrain,\n",
    "                    validation_data = ((q1_valid, q2_valid), yValid),\n",
    "                    epochs = 5,\n",
    "                    batch_size = 2048\n",
    ")\n",
    "\n",
    "#val_acc_per_epoch = history.history['val_accuracy']\n",
    "#best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Erneutes Bauen Fitting mit der optimalen Epochen-Anzahl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "#hypermodel = tuner.hypermodel.build(best_hps)\n",
    "#history = hypermodel.fit([q1_train, q2_train], yTrain,\n",
    "#                    validation_data = ((q1_valid, q2_valid), yValid),\n",
    "#                    epochs = best_epoch,\n",
    "#                    batch_size = 2048\n",
    "#)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validierung\n",
    "In der folgenden Funktion wird die genauigkeit des Modelles bestimmt.\n",
    "Die Bestimmung der Genauigkeit erfolgt auf das Trainingsdatenset, das Validierungsdatenset als auch das Testdatenset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 8s 52ms/step - loss: 0.3925 - accuracy: 0.8085\n",
      "Trainings acc: 0.8085298538208008\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.5264 - accuracy: 0.7559\n",
      "Validation acc: 0.7559177875518799\n",
      "1146/1146 [==============================] - 63s 55ms/step - loss: 1.8344 - accuracy: 0.2035\n",
      "Test acc : 0.2034623771905899\n"
     ]
    }
   ],
   "source": [
    "def evaluteModel(model, training, valid, test):\n",
    "    trainings_eval = model.evaluate([q1_train, q2_train], yTrain, batch_size=2048)\n",
    "    print(f'Trainings acc: {trainings_eval[1]}')\n",
    "    valid_eval = model.evaluate([q1_valid, q2_valid], yValid, batch_size=2048)\n",
    "    print(f'Validation acc: {valid_eval[1]}')\n",
    "    test_results = model.evaluate([q1_test, q2_test], target_test, batch_size=2048)\n",
    "    print(f'Test acc : {test_results[1]}')\n",
    "\n",
    "evaluteModel(model,[q1_train, q2_train], [q1_valid, q2_valid], [q1_test, q2_test])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Erstellung eines Modeles mit einem vorgefertigeten GloVe Model für das Embedding-Layer\n",
    "Bei der Aufgabenstellung bietet es sich an, für die Gewichtung des Embedding-Layers ein vorgefertigtes Modell zu nehmen.\n",
    "In dieser Ausführung wird dazu das GloVe-Modell der Standard-Univerity verwendet.\n",
    "Es enthält 42B-Tokens, und einen Umfang von 1.9M Wörtern\n",
    "https://github.com/stanfordnlp/GloVe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Speicherung des Modelles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "\n",
    "model.save('models/kaggle.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 76,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Laden des Modells, um ein erneutes Training zu verhindern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./models/kaggle.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wie aus der gegebenen Accuracy des Test-Datenset hervorgeht, ist diese wesentliche schlechter als noch die Genauigkeit des Trainings- oder Validierungsdatenset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def getPrediction(question1, question2):\n",
    "    test1 = tokenizer.texts_to_sequences(list([question1]))\n",
    "    test1 = pad_sequences(test1, maxlen = 36, padding = 'post')\n",
    "    test2 = tokenizer.texts_to_sequences(list([question2]))\n",
    "    test2 = pad_sequences(test2, maxlen = 36, padding = 'post')\n",
    "    return model.predict([test1, test2])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.5019383]], dtype=float32)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPrediction(\"What was your first sexual experience like?\", \"What was your first sexual experience like?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementierung in ein Frontend\n",
    "## Erstellung einer Funktion, welche aus einer Benutzereingab 3 Fragen vorschlägt\n",
    "Im folgend erfolgt die Definition einer Funktion, welche ähnliche Fragen vorschlägt.\n",
    "Dabei wird neben der Frage des Benutzers das trainierte Model, sowie der Tokenizer und die Sammlung von Fragen aus den Trainingsdaten übergeben"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def getTopThreeQuestions(user_question, question_dict, model, tokenizer, threshold):\n",
    "    found_questions = []\n",
    "    encoded_user_question = tokenizer.texts_to_sequences([user_question])\n",
    "    encoded_user_question = pad_sequences(encoded_user_question, maxlen = 36, padding = 'post')\n",
    "    something = np.asarray([encoded_user_question[0]]*len(question_dict))\n",
    "    test = model.predict([something, question_dict], batch_size = 4096, verbose = 1, use_multiprocessing = True)\n",
    "    a = test.flatten()\n",
    "    ind = np.argpartition(a, -5)[-5:]\n",
    "    top3 = ind\n",
    "    print(top3)\n",
    "    for item in top3:\n",
    "        decoded_question = tokenizer.sequences_to_texts([question_dict[item]])[0]\n",
    "        found_questions.append(decoded_question)\n",
    "    #for i, question in enumerate(question_dict):\n",
    "    #    print(i)\n",
    "    #    if model([encoded_user_question, np.array([question])]) >= threshold:\n",
    "    #        decoded_question = tokenizer.sequences_to_texts([question])[0]\n",
    "    #        found_questions.append(decoded_question)\n",
    "    #        if len(found_questions) >= 3:\n",
    "    #            break\n",
    "    return found_questions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'completeQuestionsDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m foundQuestions \u001B[38;5;241m=\u001B[39m getTopThreeQuestions(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt remember my Gmail password or my recovery email. How can I recover my e-mail?\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mcompleteQuestionsDict\u001B[49m, model, tokenizer, \u001B[38;5;241m0.99\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m question \u001B[38;5;129;01min\u001B[39;00m foundQuestions:\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(question)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'completeQuestionsDict' is not defined"
     ]
    }
   ],
   "source": [
    "foundQuestions = getTopThreeQuestions(\"I can't remember my Gmail password or my recovery email. How can I recover my e-mail?\", completeQuestionsDict, model, tokenizer, 0.99)\n",
    "for question in foundQuestions:\n",
    "    print(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.7795394]], dtype=float32)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPrediction(\"If i do not monetize Youtube videos?\", \"electrically what's the difference between kva and kw\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "485999, 781649, 291447"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}